%title Hadoop File System
%toc
=Hadoop File System=
* 当数据集大小超过一台物理机器，需要对它分区存储到不同的机器上。
* 跨机器管理存储的文件系统称之为分布式文件系统，Distributed File System
* HDFS: Hadoop distributed file system.

==HDFS的设计 ==
* *超大文件:* MB GB TB PB 
* *流式数据访问:*
  * 一次写入，多次读入
  * 每次数据分析涉及数据集中的大部分或全部
* *商业硬件:* 并不需要运行在昂贵的可靠的商业硬件上
* *商业硬件:* 并不需要运行在昂贵的可靠的商业硬件上
* *低时间延迟的访问:*
  * 不适合低时间延迟的访问，比如几十毫秒
  * 为高吞吐量做的优化， 但可能会高时间延迟为代价
* *大量小文件:*
  * 元数据存储在Namenode上
  * 文件总数的大小依赖于Namenode的内存大小 
* *不支持多用户写和多用户同时修改:*
 
==HDFS ==
===数据块 ===
* *磁盘块:* 磁盘进行读写的最小单位, 一般为512字节
* 文件系统块是磁盘块的整数倍，一般为几千字节
* HDFS的块默认为64m
  * 小于一个块大小的文件不会占满一个块
  * 块设的大是为了最小化寻址开销
  * 块过大也不行，mapreduce一次处理一个块
  * 块的大小要根据实际情况来调整，比如寻址占传输时间的1/100
* 使用块的好处
  * 一个文件的大小可以大于任意一个磁盘的大小
  * 简化了存储子系统，文件的元数据不和块数据存储在一起
  * 适合备份和容错，任何一个块都有复本。
===namenode & datanode ===
* 管理者 工作者模式
* namenode:
  * 管理者
  * 管理文件系统的命名空间
  * 维护文件系统树及树内所的目录与文件
  * 信息以两个文件永久保存：命名空间镜像文件与编辑日志文件
  * 记录文件中每个块所在数据结点的信息，但不永久保存，系统启动时重建
* datanode:
  * 工作者
  * 存储校验数据块
  * 定期向namenode发送数据块列表
* 失去namenode等于失去文件系统，所namenode容错非常重要：
  * 备份namenode上的元数据，多份同进写
  * 使用辅助namenode, 定期合并编辑日志生成空间镜像
===命令行接口 ===
===基本文件系统操作 ===
{{{ class="brush:bash"
hadoop fs -help
  }}}
  
===Hadoop文件系统 ===
* 是一个气象的文件系统
* *HDFS只是它的一个实现 *
* 抽象类定义了一个文件系统接口：`org.apache.hadoop.fs.FileSystem`
* 还有很多其他实现：Local HDFS HFTP HSFTP HAR hfs FTP S3 

===接口 ===
* java
* C
* Thrift
* WebDev
* FUSE
* 
* HDFS两种特定的
  * HTTP: namenode 50070; datanode 50075
  * FTP
===JAVA接口 ===
* *Configuration FileSystem FSDataInpuStream FSDataOutputStream Path FileStatus PathFileter*
* *Configuration*
  # 文件系统的配置
* *FileSystem*
  # 代表文件系统
  # FileSystem.get(uri, config) :创建
  # FSDataInputStream open(path) :获取指定文件的输入流
  # FSDataOutputStream create(path) :创建一个文件并获得它的输出流
  # FSDataOutputStream append(path) :获取指定文件的输出流，并在其后添加数据
  # boolean mkdirs(path) :创建必要但还没有的父目录
  # FileStatus getFileStatus(path) : 获取指定文件的文件状态
  # FileStatus[] globFileStatus(path) : 获取与文件相匹配的所有文件的文件状态
  # FileStatus[] globFileStatus(path， pathFilter) : 获取与文件相匹配的所有文件的文件状态
  # FileStatus[] listFileStatus(path) : 用来列目录
  # FileStatus[] listFileStatus(path， pathFilter) : 用来列目录
  # boolean delete(path, boolean recursive) : 删除文件或目录， 是否递归删除
* *FSDataInputStream*
  # 支持随机访问
  # seek(long):设置postion
  # long getPos():获取postion
  # int read(long position, byte[] buffer, int offset, int length)
  # void readFully(long position, byte[] buffer, int offset, int length)
  # void readFully(byte[] buffer, int offset, int length)
* *FSDataOutputStream*
  # 用于写数据 
  # 支持随机访问
  # long getPos():设置postion
  # 但不允许定位
  # 只支持对一个打开的文件从头顺序写入， 或从末尾处添加
* *FileStatus*
  # 用于查询一个文件状态
* *Path*
  # 代表一个文件路径
* *PathFileter*
  # 当listStatus时，过滤文件
* 例子：
  # 读
  # 写
  # 目录
  # 列文件
  # 删除
   
==数据流 ==
===文件读取剖析 ===
{{reading-data-from-hdfs.png}}
# fileSystem.open打开要读取的文件 
  * 这个文件就是HDFS分布式文件系统中的一个实例
# DistributedFileSystem通过RPC调用NameNode确定文件 *起始块* 所在的位置
  * NameNode返回所有包含该块的DataNode地址
  * 并按网络距离排序
  * 比如客户端所在就是一个DataNode, 而该块在此DataNode上刚好存有复本，就会发起本地读取
  * 返回一个FSDataInputStream对象，供客户端使用. 进而转而封装为HdfsDataInputStream,管理着Namenode和Datanode之间的io
# 对输入流(FSDataInputStream)调用read()方法
  * HdfsDataInputStream会从最近的Datanode读入
  * 不停的read()直到块的末尾
  * HdfsDataInpuStream会寻找  *下一个块*  的 *最优Datanode* 继续读取
  * 对于 *下一块* 也需要向Namenode查询所需的Datanode
  * 读取完毕调用FSDataInputStream的close()方法进行关闭
  * *HdfsDataInputStream与Datanode通信出错时：*
    # 尝试比这个Datanode次邻近的Datanode读取
    # 它会记住这个出错的Datanode,后续的块也不会从这里读取
    # 它也会校验读取的数据是否完整,如果发现损坏的块
    # 如果不完整，再尝试从其他Datanode读取数据之前，通知Namenode
  * *设计优劣:*
    # Namenode告知client最佳的Datanode
    # client直接从Datenode取数据
    # 因为Datanode分散在集群中
    # 所以很容易扩展到大量并发客户端
    # Namenode仅提供块位置请求，而不提供数据请求，很高效
    # 随着客户端的增加， Namenode还是会成为瓶颈


 

