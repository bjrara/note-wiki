%title Setting up a Hadoop Cluster 

=Setting up a Hadoop Cluster =

当前日期: 02/25/2013 Mon 

%toc

==集群规范 ==
* 使用商业硬件
  # 不代表低端硬件，故障率太高，会带来很大的维护成本
  # 不使用昂贵的硬件，性价比太低
* 关于RAID
  # Namenode使用Raid1
  # Datanode可以使用Raid0提高磁盘效率，但一般不使用，而使用Hadoop自身的JBOD(Just a bunch of disks)
    * RAID0 有木桶效应，受限于性能差的磁盘
    * JBOD循环使用磁盘
    * 一个测试中JBOD比RADID 0快30%
* 计算集群增长量
  # 1 week = (3T/week*replicationNum)*1.3
  # 30%用于中间文件和日志

===网络拓扑 ===
{{hadoop_topology.png}}
# 一般为两层架构
# 一个机架为30~40台机器，使用一个千兆交换机
# 各机架的交换机连接一个上层的千兆交换机（或更好）
# 机架内的node间通信要比机架间的好的多

*机架配置:*
对于多机架的集群，配置node的网络位置（和机架的映射关系），有助于极大的提升hadoop的效率
# 接口DNSToSwitchMapping用于解析node和网络位置的对应关系
  {{{ class="brush:java"
        public interface DNSToSwitchMapping {
            public List<String> resolve(List<String> names);
            //参数是ip列表
            //返回值是代表网络位置的字符串
        }
    }}}
# 属性 `topology.node.switch.mapping.impl` 指定其要使用的实现类
  * 默认实现是ScriptBasedMapping,
  * 它使用一个用户指定的脚本来决定映射关系
  * 脚本通过属性 `topology.script.file.name` 来指定
# 使用这部分信息的主要有两块
  * Namenode用于优化分配Block
  * Mapreduce尽量避免机架间传输（jobtracker)
  

==集群的构建与安装 ==
===安装java环境 ===
* >=jdk1.6 (推荐使用sun jdk)
    
===创建Hadoop专用账号 ===
# 创建hadoop专用用户，与其他服务隔离
# 对于小集群，通常会对用户主目录使用NTFS
  # 实现ssh分布式
  # 使用autofs, 按需要挂载
  # autofs还提供挂载失败时的备用方案
   
===安装Hadoop ===
# 将Hadoop安装在一个合理的地方
# 通常为/usr/local或/opt下
 
===测试已安装的Hadoop ===

==SSH配置 ==
# Hadoop跨集群的控制脚本信赖于ssh
# 需要将集群中的机器配成无密码登录
 
==Hadoop的配置 ==
# 配置文件放在conf目录中
# 也可以放在Hadoop安装目录之外的目录中，但启动守护进程时，需要使用-config选项指定配置的位置


| Filename                   | Format                   | Description                                                                                                |
|----------------------------|--------------------------|------------------------------------------------------------------------------------------------------------|
| hadoop-env.sh              | Bash script              | Environment variables that are used in the scripts to run Hadoop                                           |
| core-site.xml              | Hadoop configuration XML | Configuration settings for Hadoop Core, such as I/O settings that are common to HDFS and MapReduce         |
| hdfs-site.xml              | Hadoop configuration XML | Configuration settings for HDFS daemons: the namenode, the secondary namenode, and the datanodes           |
| mapred-site.xml            | Hadoop configuration XML | Configuration settings for MapReduce daemons: the jobtracker, and the tasktrackers                         |
| masters                    | Plain text               | A list of machines (one per line) that each run a secondary namenode                                       |
| slaves                     | Plain text               | A list of machines (one per line) that each run a datanode and a task-tracker                              |
| hadoop-metrics .properties | Java Properties          | Properties for controlling how metrics are published in Hadoop                                             |
| log4j.properties           | Java Properties          | Properties for system logfiles, the namenode audit log, and the task log for the tasktracker child process |


===配置管理 ===
# Hadoop集群没有统一的配置信息
# 而是集群中的每个结点拥有自己的一组配置信息
# 需要系统管理员来保证配置文件之间的同步
# 当然Hadoop也被设计成整个集群使用一套配置文件,但也有不适用的地方：
  # 集群中机器结点配置不一样时
  # 可以分机器类
  
*控制脚本:* 
# Hadoop提供了控制脚本用于启动或关闭整个集群中的守护进程
# 需要告诉Hadoop集群中包含哪些机器
# 两个配置文件存储了这部分信息，每一行存储一个hostname和一个ip address
# masters
  * 用于记录运行第二namenode的所有机器
# slaves
  * 用于记录所有运行datanode和tasktracker的机器
# 这两个文件放在配置目录中
# 但slaves的位置可在在hadoop.env通过HADOOP_SLAVES另行指定
# 这些配置文件无需分发到各工作结点上
# 它们只会被运行控制脚本的namenode使用
# start-dfs.sh, 用于启动集群中所有 HDFS的守护进程，并在运行脚本的机器上启动一个namenode
  # Starts a namenode on the local machine (the machine that the script is run on)
  # Starts a datanode on each machine listed in the slaves file
  # Starts a secondary namenode on each machine listed in the masters file
# start-mapred.sh, 用于启动集群中所有 MapReduce的守护进程
  # Starts a jobtracker on the local machine
  # Starts a tasktracker on each machine listed in the slaves file
# MapReduce的控制脚本并不会使用masters配置文件
# 最终是通过hadoop-daemon.sh这个脚本完成工作的

*主要结点:* 
# 主要结点的守护进程：namenode, secondary namenode, jobtracker
# 这些守护进程可以运行于一台机器上，集群较小时
# 但随着机器的增大，应该运行于不同的机器上
# 不管是否在一台机器上，它的运行遵循下列规则
  * Run the HDFS control scripts from the namenode machine. The masters file should contain the address of the secondary namenode.
  * Run the MapReduce control scripts from the jobtracker machine

# 当namenode与jobtracker运行于不同的机器上时，它们的slaves配置文件应该保持同步

===环境变量设置 ===

====内存 ====

# 默认为每个守护进程分配1G内存, 通过 `hadoop-env.sh` 中的变量 `HADOOP_HEAPSIZE` 控制
# 工作结点内存大小的结点需要考虑到map task和reduce task的，因为这些task是在独立jvm里运行的
  * 一个结点，最多的map task:    mapred.tasktracker.map.tasks.maximum,    默认为2
  * 一个结点，最多的reduce task: mapred.tasktracker.reduce.tasks.maximum, 默认为2
  * 一个task的内存：mapred.child.java.opts, 默认为200m
  * 工作结点内存 = datanode + tasktracker + maptasks + reducetasks = 1G + 1G + 200m*2 + 200m*2 = 2.8G
  * 经验之谈：task总数与cpu数目之比的1与2之间
  *  计算内存，最后不要忘记机器上其他不属于hadoop进程的内存
# 主结点内存，若运行namenode, secondary namenode, jobtracker, 默认需要3G内存
# 计算namenode 进程的内存
  * namenode内存的大小依赖于集群中文件的总数和块数
  * 默认1G内存，一般足够几百万文件使用了
  * 保守使用，通常认为1G内存可用于一百万个文件块分配
  * namenode 进程内存 = ( diskSize*datanodeNumber/blockSize/replicationNumber/100000 ) G
  * 在 `hadoop-env.sh` 中的可以专门设置namenode内存的大小： `HADOOP_NAMENODE_OPTS` 
  * 在 `hadoop-env.sh` 中的可以专门设置sceondary namenode内存的大小： `HADOOP_SECONDARYNAMENODE_OPTS`, 应该和namenode保持一致 
# 在 `hadoop-env.sh` 中也可以为其他守护进程设置内存大小
 
====Java ====
# hadoop使用 `hadoop-env.sh` 的变量 `JAVA_HOME` 或系统环境变量 `JAVA_HOME` 来决定使用的jdk
# 推荐在 `hadoop-env.sh` 设置，可以使整个集群保持一致
 
====系统日志 ====
# 日志文件默认存放在 `$HADOOP_INSTALL/logs` 下
# 可以通过 `hadoop-env.sh` 的变量 `HADOOP_LOG_DIR` 修改
# 日志文件夹不存在，会自动创建， _*但要注意创建权限*_ 
# 两类日志文件
  * .log结尾，由log4j记录，每天rotate, 包含大部分的日志信息
  * .out结尾，stdout和stderr的组成，每次重启rotate，最多五个，只有很少的日志内容
  * 日志文件名 = 用户名-进程名-主机名.(log/out)
  * 上面的用户名由 `hadoop-env.sh` 中的 `HADOOP_IDENT_STRING` 指定
   
====ssh配置 ====
# 主结点的控制脚本可以通过ssh在所有工作结点上运行命令
# *ConnetionTimeout:* 调整合适的超时大小
# *StrictHostKeyChecking:* 不询问，自动添加远程主机known hosts
# 在 `hadoop-env.sh` 中配置 `HADOOP_MASTER`
  * 在工作结点守护进程启动时，会把以  `HADOOP_MASTER` 为根的目录树与本地的 `HADOOP_INSTALL` 进行同步
  * 大型集群为了防止启动时主结点rsync压力过大，可以设置 `HADOOP_SLAVE_SLEEP` 单位为秒，会在调用工作结点两个指令间隙休眠一段时间
   
===守护进程的主要配置 ===

主要的配置文件： core-site.xml hdfs-site.xml mapred-site.xml

====HDFS====

${hadoop.tmp.dir} 默认值： 
/tmp/hadoop-${user.name}
 
Table: Important HDFS daemon properties
| Property name     | Type                            | Default value                       | Description                                                                                                                                                            |
| fs.default.name   | URI                             | file:///                            | The default filesystem. The URI defines the hostname and port that the namenode’s RPC server runs on. The default port is 8020. This property is set in coresite.xml. |
| dfs.name.dir      | Comma-separated directory names | ${hadoop.tmp.dir}/dfs/name          | The list of directories where the namenode stores its persistent metadata.  The namenode stores a copy of the metadata in each directory in the list.                  |
| dfs.data.dir      | Comma-separated directory names | ${hadoop.tmp.dir}/dfs/data          | A list of directories where the datanode stores blocks. Each block is stored in only one of these directories.                                                         |
| fs.checkpoint.dir | Comma-separated directory names | ${hadoop.tmp.dir}/dfs/namesecondary | A list of directories where the secondary namenode stores checkpoints.  It stores a copy of the checkpoint in each directory in the list.                              |

====MapReduce====
| Property name                             | Type                            | Default value                   | Description                                                                                                                                                                                                                                                                                                   |
|-------------------------------------------|---------------------------------|---------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| mapred.job.tracker                        | Hostname and port               | local                           | The hostname and port that the jobtracker’s RPC server runs on. If set to the default value of local, the jobtracker is run in-process on demand when you run a MapReduce job (you don’t need to start the jobtracker in this case, and in fact you will get an error if you try to start it in this mode). |
| mapred.local.dir                          | Comma-separated directory names | ${hadoop.tmp.dir}/mapred/local  | A list of directories where MapReduce stores intermediate data for jobs. The data is cleared out when the job ends.                                                                                                                                                                                           |
| mapred.system.dir                         | URI                             | ${hadoop.tmp.dir}/mapred/system | The directory relative to fs.default.name where shared files are stored during a job run.                                                                                                                                                                                                                     |
| mapred.tasktracker.map.tasks.maximum      | int                             | 2                               | The number of map tasks that may be run on a tasktracker at any one time.                                                                                                                                                                                                                                     |
| mapred.tasktracker.  reduce.tasks.maximum | int                             | 2                               | The number of reduce tasks that may be run on a tasktracker at any one time.                                                                                                                                                                                                                                  |
| mapred.child.java.opts                    | String                          | -Xmx200m                        | The JVM options used to launch the tasktracker child process that runs map and reduce tasks. This property can be set on a per-job basis, which can be useful for setting JVM properties for debugging, for example.                                                                                          |
| mapreduce.map.java.opts                   | String                          | -Xmx200m                        | The JVM options used for the child process that runs map tasks. (Not available in 1.x.)                                                                                                                                                                                                                       |
| mapreduce.reduce.java.opts                | String                          | -Xmx200m                        | The JVM options used for the child process that runs reduce tasks. (Not available in 1.x.)                                                                                                                                                                                                                    |

===Hadoop守护进程与端口 ===
* 守护进程运行一个RPC Server, 供守护进程间通信
* 守护进程运行一个HTTP Server, 提供界面供人为查看
* Server的端口号设为 0， 意谓着例使用一个空闲端口。
* datanode除RPC Server外，还会运行一个TCP/IP Server
  # 用于block传输
  # 通过属性fs.datanode.addrss设置
  # 默认值：0.0.0.0:50010
* 通过下列属性可以设置datanode和tasktracker使用的网口，同时会影响RPC Server和Http Server
  # dfs.datanode.dns.interface
  # mapred.tasktracker.dns.interface


*Table 9-5. RPC server properties:*
| Property name                      | Default value | Description                                                                                                                                                                                                                                                                                                     |
|------------------------------------|---------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| fs.default.name                    | file:///      | When set to an HDFS URI, this property determines the namenode’s RPC server address and port. The default port is 8020 if not specified.                                                                                                                                                                       |
| dfs.datanode.ipc.address           | 0.0.0.0:50020 | The datanode’s RPC server address and port.  mapred.job.tracker local When set to a hostname and port, this property specifies the jobtracker’s RPC server address and port. A commonly used port is 8021.                                                                                                    |
| mapred.task.tracker.report.address | 127.0.0.1:0   | The tasktracker’s RPC server address and port. This is used by the tasktracker’s child JVM to communicate with the tasktracker. Using any free port is acceptable in this case, as the server only binds to the loopback address. You should change this setting only if the machine has no loopback address. |


*Table 9-6. HTTP server properties:*
| Property name                    | Default value | Description                                            |
|----------------------------------|---------------|--------------------------------------------------------|
| mapred.job.tracker.http.address  | 0.0.0.0:50030 | The jobtracker’s HTTP server address and port         |
| mapred.task.tracker.http.address | 0.0.0.0:50060 | The tasktracker’s HTTP server address and port        |
| dfs.http.address                 | 0.0.0.0:50070 | The namenode’s HTTP server address and port           |
| dfs.datanode.http.address        | 0.0.0.0:50075 | The datanode’s HTTP server address and port           |
| dfs.secondary.http.address       | 0.0.0.0:50090 | The secondary namenode’s HTTP server address and port |

===其他Hadoop的配置 ===

====集群成员 ====
* *dfs.hosts:* 加入集群中将作为datanode的机器列表
* *mapred.hosts:* 加入集群中将作为tasktracker的机器列表
* *dfs.hosts.exclude:* 要从datanode中移除的机器
* *mapred.hosts.exclude:* 要从tasktracker中移除的机器 

====缓冲区大小 ====
* *io.file.buffer.size:* i/o缓冲区大小，默认值 4KB, 可更改，比如128KB

====HDFS block大小 ====
* *dfs.block.size:* HDFS块大小，默认值 64KB, 可更改，比如128MB 256MB
 
====保留空间 ====
* *dfs.datanode.du.reserved:* HDFS块大小，默认值 0, 不保留 , 单位为bytes

====回收站 ====
* 通过fa.trash.interval设置保留时间,单位为钟，默认为0， 不保留，立刻删除
* shell中直接使用
* 编程需要特殊 api
 
====Reduce慢启动 ====
* 默认情况下，高度器会等待一个job至少%5map task完成，才会启动reduce task
* 但即使taskreduce不启动，仍就占着一个reduce slot
* *mapred.reduce.slowstart.completed.maps:* 设置等待时间，比如0.8，代表80%


