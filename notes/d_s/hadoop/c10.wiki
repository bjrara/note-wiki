%title Administering Hadoop 
=Administering Hadoop =

%toc

==HDFS==

===持久化数据结构 ===
Namenode, Secondary Namenode, Datanode在磁盘上数据是如何存储组织的。

====Namenode的目录结构 ====
{{{ class="brush:bash"
    ${dfs.name.dir}/
    └── current/
        ├── VERSION
        ├── edits
        ├── fsimage
        └── fstime
  }}}
# dfs.name.dir 可以指定几个文件夹列表
# 每个文件夹中存放相同的数据
# 推荐其中一个使用NFS文件夹
# 文件VERSION：
{{{ class="brush:bash"
    #Tue Mar 10 19:21:36 GMT 2009
    namespaceID=134368441 #文件系统的唯一id号
                          #文件系统第一次格式化时创建
                          #用于检测新添加的datanode,因为它们不知道这个id号
    cTime=0 # namenode存储创建的时间
            # 对于新格式化的设备总是0
            # 升级时会更新这个时间
    storageType=NAME_NODE # 表名该文件夹存储什么样的数据
                          # 这个文件夹说明存放namenode的数据
    layoutVersion=-18 # 文件系统存储数据所使用结构的版本
                      # 是一个负数
                      # 升级会变成一个更小的负数，下一个版本-19
  }}}

====文件系统映象与编辑日志 ====
*编辑日志edit log:*
# 当对HDFS进行一个写操作时
# 就会在edit log中产生一条记录
# namenode会在内存中保留一份整个HDFS的元数据
  * 它会在edit log更改后更改
  * 它服务于对HDFS的读操作
# edit log的flush与sync
  * 它会在向客户端返回success code之前进行
  * namenode需要写多个目录
  * 要保证每一个目录都写到了，才返回

*fsimage:*
# HDFS元数据checkpoint的持久化数据
# 并不是每个写操作都会触发更新，否则的话这个文件会增长过快
# 当namenode失败时
  # 会通过该文件恢复内存中的元数据
  # replay edit log中的操作
# namenode启动时就是进行的上述操作
 
*fsimage中的内容:*
# HDFS中所有文件和目录的inodes
# 一个inode代表一个文件或目录的元数据
# 对于文件
  * replication level
  * modification and access times
  * access permissions
  * block size
  * 由哪些blocks组成
# 对于目录
  * modification time
  * permissions
  * quota metadata is stored.

edit log并没有大小限制，而namenode运行时，并不会有影响，
但当namenode重启时，会花很长的时间replay这个文件里的操作.
解决方案就是使用secondary namenode.

*secondary namenode:*
# 用于根据主结点中的内存元数据生成checkpoint
# 进程的处理过程:
  # The secondary asks the primary to roll its edits file, so new edits go to a new file.
  # The secondary retrieves fsimage and edits from the primary (using HTTP GET).
  # The secondary loads fsimage into memory, applies each operation from edits, then
    creates a new consolidated fsimage file.
  # The secondary sends the new fsimage back to the primary (using HTTP POST).
  # The primary replaces the old fsimage with the new one from the secondary and the
    old edits file with the new one it started in step 1. It also updates the fstime file to
    record the time that the checkpoint was taken.
# 最后primary就会拥有一个最新的fsimage文件和一个小的edit log 文件
# 管理员可以手动触发这个操作: `hadoop dfsadmin -saveNamespace`
# 这个过程的自动触发有两种情况
  * 每小时触发一次，由属性 `fs.checkpoint.period` 指定
  * 当edit log到达64MB时，由属性 `fs.checkpoint.size` 指定
# 由上面可看出secondary namenode需要有和namenode相近的内存
{{namenode-checkpointing.png}}

====Secondary Namenode的目录结构 ====
{{{ class="brush:bash"
    ${fs.checkpoint.dir}/
    ├── current/
    │   ├── VERSION
    │   ├── edits
    │   ├── fsimage
    │   └── fstime
    └── previous.checkpoint/
         ├── VERSION
         ├── edits
         ├── fsimage
         └── fstime
  }}}
# checkpointing进程完毕后，secondary namenode也会拥有一个检查点,放在文件夹previous.checkpoint里
# 这份数据可以作为namenode元数据的备份
# secondary namenode的current，previous checkpoint和主namenode的元数据文件夹的结构是一样的
# namenode失败时
  # 可以通过-importCheckpoint选项启动secondary namenode, 其将作为主namenode
  # 它会从fs.checkpoint.dir文件夹里获取最新元数据放入dfs.name.dir里

====Datanode的目录结构 ====
{{{ class="brush:bash"
    ${dfs.data.dir}/
    └── current/
         ├── VERSION
         ├── blk_<id_1>
         ├── blk_<id_1>.meta
         ├── blk_<id_2>
         ├── blk_<id_2>.meta
         ├── ...
         ├── blk_<id_64>
         ├── blk_<id_64>.meta
         ├── subdir0/
         ├── subdir1/
         ├── ...
         └── subdir63/
  }}}
# datanode的目录不需要预先格式化，它会在启动时自动创建
# 同namenode一样，这里也会有一个VERSION文件
  * namespceID, cTime 和 layoutVersion同namenode里的一样
  * namespceID是从namenode里接收的, 当datanode第一次连接时
  * storgeID是全局内是唯一的，namenode用它来唯一确定一个datanode
  * storageType用于表明该目录是做什么用的，这里是用于存储datanode数据的
# 两种以blk_为前缀的文件
  * 一种就是HDFS块, 存储原始数据
  * 第二种是HDFS块的元数据，以.meta为后缀， 存放了版本与类型信息，接着是一系列的校验值
# 当HDFS块的数量到达一定数量后，会创建一个子目录，用于存放新的块和它们的元数据
  * 通过属性 `dfs.datanode.numblocks` 设置这个数据
  * 保证了每个文件夹拥有可维护数量的文件
# 若dfs.data.dir设置了多个目录，分属于不同的磁盘
  * HDFS会轮循使用这些目录
  * 不同的目录下不会有重复的块，只有不同的datanode间才有不同的块

===安全模式 ===
*Namenode的启动:*
# 加载fsimage进内存
# 接收edit log中的所有操作进内存
# 内存中构建出一份新的fsimage
# 创建一份新的空的edit log
# 开始监听RPC和HTTP请求
 
*安全模式:*
# 上面最后一步前是运行于安全模式的
# 可运行读元数据的操作，但也不保证完成
# 读文件的操作，只有当文件的块全部就绪后才可以
# 修改操作会全部失败
 
*namenode不维护hdfs block的位置信息:*
# namenode不会持久化hdfs block的位置信息
# namenode在内存中会有一份这样的信息
# 在安全模式下，datanode会告诉namenode它所包含的datanode列表
# 在安全模式下，不会对datanode 进行任何复本操作和删除操作
# 安全模式退出的条件：
  # 达到最小复本条件，再等30秒
  # 最小复本条件默认是99%的块达到了复本要求
# 新格式化的hdfs集群， namenode并不会进行安全模式
| Property name              | Type  | Default value | Description                                                                                                                                                                                                                                                                                                            |
| dfs.replication.min        | int   | 1             | The minimum number of replicas that have to be written for a write to be successful.                                                                                                                                                                                                                                   |
| dfs.safemode.threshold.pct | float | 0.999         | The proportion of blocks in the system that must meet the minimum replication level defined by dfs.replication.min before the namenode will exit safe mode. Setting this value to 0 or less forces the namenode not to start in safe mode. Setting this value to more than 1 means the namenode never exits safe mode. |
| dfs.safemode.extension     | int   | 30,000        | The time, in milliseconds, to extend safe mode after the minimum replication condition defined by dfs.safemode.threshold.pct has been satisfied.  For small clusters (tens of nodes), it can be set to 0.                                                                                                              |

===进入与离开安全模式 ===
# 查看namenode是否在安全模式
  {{{ class="brush:bash"
     % hadoop dfsadmin -safemode get
    }}}
# 等待namenode退出安全模式
  {{{ class="brush:bash"
     hadoop dfsadmin -safemode wait
     # command to read or write a file
    }}}
# 使namenode进入安全模式
  {{{ class="brush:bash"
     % hadoop dfsadmin -safemode enter
    }}}
# 使namenode离开安全模式
  {{{ class="brush:bash"
     % hadoop dfsadmin -safemode leave
    }}}

===审核日志 ===
hadoop可以对所有的访问记录日志。
默认没有打开，可以在log4j的配置文件里打开

===工具集 ===
====dfsadmin====
| Command            | Description                                                                                                                                                                                                                                                                                                                                                                                |
|--------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| -help              | Shows help for a given command, or all commands if no command is specified.                                                                                                                                                                                                                                                                                                                |
| -report            | Shows filesystem statistics (similar to those shown in the web UI) and information on connected datanodes.                                                                                                                                                                                                                                                                                 |
| -metasave          | Dumps information to a file in Hadoop’s log directory about blocks that are being replicated or deleted, as well as a list of connected datanodes.                                                                                                                                                                                                                                         |
| -safemode          | Changes or queries the state of safe mode. See “Safe Mode” on page 344.                                                                                                                                                                                                                                                                                                                    |
| -saveNamespace     | Saves the current in-memory filesystem image to a new fsimage file and resets the edits file. This operation may be performed only in safe mode.                                                                                                                                                                                                                                           |
| -refreshNodes      | Updates the set of datanodes that are permitted to connect to the namenode. See “Commissioning and Decommissioning Nodes” on page 359.                                                                                                                                                                                                                                                     |
| -upgradeProgress   | Gets information on the progress of an HDFS upgrade or forces an upgrade to proceed. See “Upgrades” on page 362.                                                                                                                                                                                                                                                                           |
| -finalizeUpgrade   | Removes the previous version of the namenode and datanode storage directories. Used after an upgrade has been applied and the cluster is running successfully on the new version. See “Upgrades” on page 362.                                                                                                                                                                              |
| -setQuota          | Sets directory quotas. Directory quotas set a limit on the number of names (files or directories) in the directory tree. Directory quotas are useful for preventing users from creating large numbers of small files, a measure that helps preserve the namenode’s memory (recall that accounting information for every file, directory, and block in the filesystem is stored in memory). |
| -clrQuota          | Clears specified directory quotas.                                                                                                                                                                                                                                                                                                                                                         |
| -setSpaceQuota     | Sets space quotas on directories. Space quotas set a limit on the size of files that may be stored in a directory tree. They are useful for giving users a limited amount of storage.                                                                                                                                                                                                      |
| -clrSpaceQuota     | Clears specified space quotas.                                                                                                                                                                                                                                                                                                                                                             |
| -refreshServiceAcl | Refreshes the namenode’s service-level authorization policy file.                                                                                                                                                                                                                                                                                                                          |

====fsck====
用于检查HDFS和HDFS中文件的健康状况。
{{{ class="brush:bash"
    % hadoop fsck /
    ......................Status: HEALTHY
    Total size:
    511799225 B
    Total dirs: 10
    Total files: 22
    Total blocks (validated): 22 (avg. block size 23263601 B)
    Minimally replicated blocks: 22 (100.0 %)
    Over-replicated blocks: 0 (0.0 %)
    Under-replicated blocks: 0 (0.0 %)
    Mis-replicated blocks: 0 (0.0 %)
    Default replication factor: 3
    Average block replication: 3.0
    Corrupt blocks: 0
    Missing replicas: 0 (0.0 %)
    Number of data-nodes: 4
    Number of racks: 1
  }}}
  
# fsck仅仅从namenode获取数据
# 不会和任何datanode通信
# 也不会获取任何文件数据
# 重要属性说明：
  * *Over-replicated blocks:* 复本数量超过指定的数量，通常不是什么问题，namenode会删除不需要的
  * *Under-replicated blocks:* 复本数量不足指定的数量，namenode会自动补足
  * *Misreplicated blocks:* 不符合复本策略，比如多机架环境，复本都在同一机架，namenode会自动调整 
  * *Corrupt blocks:* 损坏复本的块，如果复本中至少有一个正常的，就不会报告这项，而是namenode就会修复 
  * *Missing replicas:* 丢失所有复本 
# Corrupt和Missing是着重注意的，意味着数据已丢失，下面两个选项可以对这两种文件进行附加操作
  * *-move* 移动到hdfs中的/lost+found文件夹中 
  * *-delete* 直接删除
# 获取一个文件的块信息
  {{{ class="brush:bash"
      % hadoop fsck /user/tom/part-00007 -files -blocks -racks
      /user/tom/part-00007 25582428 bytes, 1 block(s): OK
      0. blk_-3724870485760122836_1035 len=25582428 repl=3 [/default-rack/10.251.43.2:50010,
      /default-rack/10.251.27.178:50010, /default-rack/10.251.123.163:50010]
    }}}
  * *-files*  显示 文件名 大小 块数量 健康状态
  * *-blocks* 显示每个块的信息
  * *-racks* 显示每个块的机架信息和datanode

====datanode block scanner====
# 用于定期检查验证一个datanode上所有的块
# 可以查出并修复损坏的块
# 它维护了一个需要检查块的列表
# 块默认每三周检查一次，可以通过属性dfs.datanode.scan.period.hours设置
# 通过http://datanode:50075/blockScannerReport 查看报表
# 通过http://datanode:50075/blockScannerReport?listblocks 查看每一块的信息
    
====balancer====
# 随着使用，集群中的datanode将变的不平衡，有些过度使用，有些使用很少
# balancer 是一个守护进程，可以调整这种不平衡，将一些块从过度使用的datanode移到不常使用的datanode
# 需要遵守复本策略
# 拥有一个根据磁盘带宽，节流的机制
# 工作到直到集群平衡
  * datanode的使用比例和整个集群的使用比例在一个误差范围内，默认是10％
  * 手工运行时，可以通过参数-threshold指定
# 手工运行
  {{{ class="brush:bash"
      % start-balancer.sh
    }}}
# 一个时刻只能有一个实例运行
# 最终会通过日志的方式产生一个报告
# 默认限制datanode拷贝数据时的带宽大约为10M/s, 可能通过在hdfs-site.xml中的属性dfs.balance.bandwidthPerSec设置，

==监控 ==

==维护 ==
