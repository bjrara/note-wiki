%title Administering Hadoop 
=Administering Hadoop =

%toc

==HDFS==

===持久化数据结构 ===
Namenode, Secondary Namenode, Datanode在磁盘上数据是如何存储组织的。

====Namenode的目录结构 ====
{{{ class="brush:bash"
    ${dfs.name.dir}/
    └── current/
        ├── VERSION
        ├── edits
        ├── fsimage
        └── fstime
  }}}
# dfs.name.dir 可以指定几个文件夹列表
# 每个文件夹中存放相同的数据
# 推荐其中一个使用NFS文件夹
# 文件VERSION：
{{{ class="brush:bash"
    #Tue Mar 10 19:21:36 GMT 2009
    namespaceID=134368441 #文件系统的唯一id号
                          #文件系统第一次格式化时创建
                          #用于检测新添加的datanode,因为它们不知道这个id号
    cTime=0 # namenode存储创建的时间
            # 对于新格式化的设备总是0
            # 升级时会更新这个时间
    storageType=NAME_NODE # 表名该文件夹存储什么样的数据
                          # 这个文件夹说明存放namenode的数据
    layoutVersion=-18 # 文件系统存储数据所使用结构的版本
                      # 是一个负数
                      # 升级会变成一个更小的负数，下一个版本-19
  }}}

====文件系统映象与编辑日志 ====
*编辑日志edit log:*
# 当对HDFS进行一个写操作时
# 就会在edit log中产生一条记录
# namenode会在内存中保留一份整个HDFS的元数据
  * 它会在edit log更改后更改
  * 它服务于对HDFS的读操作
# edit log的flush与sync
  * 它会在向客户端返回success code之前进行
  * namenode需要写多个目录
  * 要保证每一个目录都写到了，才返回

*fsimage:*
# HDFS元数据checkpoint的持久化数据
# 并不是每个写操作都会触发更新，否则的话这个文件会增长过快
# 当namenode失败时
  # 会通过该文件恢复内存中的元数据
  # replay edit log中的操作
# namenode启动时就是进行的上述操作
 
*fsimage中的内容:*
# HDFS中所有文件和目录的inodes
# 一个inode代表一个文件或目录的元数据
# 对于文件
  * replication level
  * modification and access times
  * access permissions
  * block size
  * 由哪些blocks组成
# 对于目录
  * modification time
  * permissions
  * quota metadata is stored.

edit log并没有大小限制，而namenode运行时，并不会有影响，
但当namenode重启时，会花很长的时间replay这个文件里的操作.
解决方案就是使用secondary namenode.

*secondary namenode:*
# 用于根据主结点中的内存元数据生成checkpoint
# 进程的处理过程:
  # The secondary asks the primary to roll its edits file, so new edits go to a new file.
  # The secondary retrieves fsimage and edits from the primary (using HTTP GET).
  # The secondary loads fsimage into memory, applies each operation from edits, then
    creates a new consolidated fsimage file.
  # The secondary sends the new fsimage back to the primary (using HTTP POST).
  # The primary replaces the old fsimage with the new one from the secondary and the
    old edits file with the new one it started in step 1. It also updates the fstime file to
    record the time that the checkpoint was taken.
# 最后primary就会拥有一个最新的fsimage文件和一个小的edit log 文件
# 管理员可以手动触发这个操作: `hadoop dfsadmin -saveNamespace`
# 这个过程的自动触发有两种情况
  * 每小时触发一次，由属性 `fs.checkpoint.period` 指定
  * 当edit log到达64MB时，由属性 `fs.checkpoint.size` 指定
# 由上面可看出secondary namenode需要有和namenode相近的内存
{{namenode-checkpointing.png}}

====Secondary Namenode的目录结构 ====
{{{ class="brush:bash"
    ${fs.checkpoint.dir}/
    ├── current/
    │   ├── VERSION
    │   ├── edits
    │   ├── fsimage
    │   └── fstime
    └── previous.checkpoint/
         ├── VERSION
         ├── edits
         ├── fsimage
         └── fstime
  }}}
# checkpointing进程完毕后，secondary namenode也会拥有一个检查点,放在文件夹previous.checkpoint里
# 这份数据可以作为namenode元数据的备份
# secondary namenode的current，previous checkpoint和主namenode的元数据文件夹的结构是一样的
# namenode失败时
  # 可以通过-importCheckpoint选项启动secondary namenode, 其将作为主namenode
  # 它会从fs.checkpoint.dir文件夹里获取最新元数据放入dfs.name.dir里

====Datanode的目录结构 ====
{{{ class="brush:bash"
    ${dfs.data.dir}/
    └── current/
         ├── VERSION
         ├── blk_<id_1>
         ├── blk_<id_1>.meta
         ├── blk_<id_2>
         ├── blk_<id_2>.meta
         ├── ...
         ├── blk_<id_64>
         ├── blk_<id_64>.meta
         ├── subdir0/
         ├── subdir1/
         ├── ...
         └── subdir63/
  }}}
# datanode的目录不需要预先格式化，它会在启动时自动创建
# 同namenode一样，这里也会有一个VERSION文件
  * namespceID, cTime 和 layoutVersion同namenode里的一样
  * namespceID是从namenode里接收的, 当datanode第一次连接时
  * storgeID是全局内是唯一的，namenode用它来唯一确定一个datanode
  * storageType用于表明该目录是做什么用的，这里是用于存储datanode数据的
# 两种以blk_为前缀的文件
  * 一种就是HDFS块, 存储原始数据
  * 第二种是HDFS块的元数据，以.meta为后缀， 存放了版本与类型信息，接着是一系列的校验值
# 当HDFS块的数量到达一定数量后，会创建一个子目录，用于存放新的块和它们的元数据
  * 通过属性 `dfs.datanode.numblocks` 设置这个数据
  * 保证了每个文件夹拥有可维护数量的文件
# 若dfs.data.dir设置了多个目录，分属于不同的磁盘
  * HDFS会轮循使用这些目录
  * 不同的目录下不会有重复的块，只有不同的datanode间才有不同的块

===安全模式 ===
*Namenode的启动:*
# 加载fsimage进内存
# 接收edit log中的所有操作进内存
# 内存中构建出一份新的fsimage
# 创建一份新的空的edit log
# 开始监听RPC和HTTP请求
 
*安全模式:*
# 上面最后一步前是运行于安全模式的
# 可运行读元数据的操作，但也不保证完成
# 读文件的操作，只有当文件的块全部就绪后才可以
# 修改操作会全部失败
 
*namenode不维护hdfs block的位置信息:*
# namenode不会持久化hdfs block的位置信息
# namenode在内存中会有一份这样的信息
# 在安全模式下，datanode会告诉namenode它所包含的datanode列表
# 在安全模式下，不会对datanode 进行任何复本操作和删除操作
# 安全模式退出的条件：
  # 达到最小复本条件，再等30秒
  # 最小复本条件默认是99%的块达到了复本要求
# 新格式化的hdfs集群， namenode并不会进行安全模式
| Property name              | Type  | Default value | Description                                                                                                                                                                                                                                                                                                            |
| dfs.replication.min        | int   | 1             | The minimum number of replicas that have to be written for a write to be successful.                                                                                                                                                                                                                                   |
| dfs.safemode.threshold.pct | float | 0.999         | The proportion of blocks in the system that must meet the minimum replication level defined by dfs.replication.min before the namenode will exit safe mode. Setting this value to 0 or less forces the namenode not to start in safe mode. Setting this value to more than 1 means the namenode never exits safe mode. |
| dfs.safemode.extension     | int   | 30,000        | The time, in milliseconds, to extend safe mode after the minimum replication condition defined by dfs.safemode.threshold.pct has been satisfied.  For small clusters (tens of nodes), it can be set to 0.                                                                                                              |

===进入与离开安全模式 ===
# 查看namenode是否在安全模式
  {{{ class="brush:bash"
     % hadoop dfsadmin -safemode get
    }}}
# 等待namenode退出安全模式
  {{{ class="brush:bash"
     hadoop dfsadmin -safemode wait
     # command to read or write a file
    }}}
# 使namenode进入安全模式
  {{{ class="brush:bash"
     % hadoop dfsadmin -safemode enter
    }}}
# 使namenode离开安全模式
  {{{ class="brush:bash"
     % hadoop dfsadmin -safemode leave
    }}}

===审核日志 ===

===工具集 ===

==监控 ==

==维护 ==
