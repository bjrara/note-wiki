<!DOCTYPE html>
<html>
<head>

<title> How MapReduce Works</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<script type="text/javascript" src="../../js/jquery-1.6.4.min.js"></script>

<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shCore.css">
<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shThemeRDark.css">
<script type="text/javascript" src="../../js/sh/scripts/shCore.js"></script>
<script type="text/javascript" src="../../js/sh/scripts/shAutoloader.js"></script>

<script type="text/javascript" src="../../js/main.js"></script>
<script type="text/javascript" src="../../js/ASCIIMathML.js"></script>

<link rel="Stylesheet" type="text/css" href="../../style.css">
<link rel="Stylesheet" type="text/css" href="../../css/main.css">

</head>
<body>
	<div class="hidden">
		<input id="root_path" type="text" value="../../">
	</div>
	<div id="body-wrapper">
		<div id="container">
			<div id="top">
				<div id="page-title">
					<a href="../../index.html">烂笔头</a>
				</div>
				<ul id="top-nav">
				</ul>
			</div>
			<div id="middle">
				
<div class="toc">
<ul>
<li><a href="#toc_1">How MapReduce Works</a>
<ul>
<li><a href="#toc_1.1">MapReduce工作机制</a>
<ul>
<li><a href="#toc_1.1.1">经典的MapReduce(MapReduce 1)</a>
<li><a href="#toc_1.1.2">二代:Yarn(MapReduce 2)</a>
</ul>
<li><a href="#toc_1.2">处理失败</a>
<li><a href="#toc_1.3">Job的调度 </a>
<li><a href="#toc_1.4">Shuffle和排序 </a>
<li><a href="#toc_1.5">Task的运行 </a>
</ul>
</ul>
</div>


<p>
当前日期: 01/30/2013 Wed 
</p>
<h1 id="toc_1">How MapReduce Works</h1>

<h2 id="toc_1.1">MapReduce工作机制</h2>

<h3 id="toc_1.1.1">经典的MapReduce(MapReduce 1)</h3>
<p>
<img src="mapreduce_classic.png" />
</p>

<p>
<strong>参与者:</strong>
</p>
<ul>
<li>
<strong>Client:</strong>, MapReduce Job的提交者

<li>
<strong>Jobtracker:</strong>, 负责安排Job的运行，对应的 class 是 JobTracker.

<li>
<strong>Tasktrackers:</strong> 负责运行由Job分解出的Task, 对应的 class 是 TaskTracker.

<li>
<strong>Distributed Filesystem:</strong> 通常HDFS,用于共享Job相关的文件

</ul>

<p>
<strong>提交Job:</strong>
</p>
<ol>
<li>
<strong>Step 1:</strong> 创建一个JobSubmitter实例，并调用其方法submitJobInternal(). (由Job的方法submit()触发)

<li>
方法<code>waitForCompletion()</code>会每秒拉一次Job的状态与进度

<li>
提交的具体步骤：

<ol>
<li>
<strong>Step 2:</strong> 向jobtracker请求一个新的job ID (<code>getNewJobId()</code>)

<li>
查看job的输出设置条件是否满足，比如输出文件夹是否存在，不存在不能运行

<li>
计算输入的分片，不能分片不能运行，比如输入路径不存在

<li>
<strong>Step 3:</strong> 拷贝job的相关资源到jobtracker的文件系统（jar,configuration,分片结果等），jar文件会有很多份

<ul>
<li>
通过属性 <code>mapred.submit.replication</code> 指定，默认为10

<li>
当运行Task时，可以很快速从集群中获得

</ul>
<li>
<strong>Step 4:</strong> 告诉Jobtracker,job已准备好运行（调用JobTracker的submitJob() ).

</ol>
</ol>

<p>
<strong>初始化Job:</strong>
</p>
<ol>
<li>
Jobtracker收到submitJob()的请求后，会把job放入一个队列里

<li>
job scheduler会从队列里取出并初始化

<li>
<strong>Step 5:</strong> 创建一个代表job的对象

<ul>
<li>
包含task信息

<li>
进度和状态信息

</ul>
<li>
<strong>Step 6:</strong> 接受由client计算出的分片信息，创建要运行的task列表

<ul>
<li>
为每一个分片创建一个map task

<li>
属性 <code>mapred.reduce.tasks</code> 确定reduce task的数目

<li>
此时所有的task都会被分配id

<li>
还有两个额外的task会被创建：job setup task 和 job clean up task

<ul>
<li>
用于在任何map　task前启动一个job

<li>
用于在所有reduce task后，清理工作

</ul>
</ul>
</ol>

<p>
<strong>分配Task:</strong>
</p>
<ol>
<li>
<strong>Step 7:</strong> task tracker 会不间隔向job tracker发送心跳heart beat(使用一个循环体）

<ul>
<li>
告诉job tracker,它还活着

<li>
也可以用于交换信息

<li>
比如告诉job　tracker,已经准备好接收新的task, job tracker 就会分配给它一个新的任务

</ul>
<li>
task tracker 会有一定数量的map task和reduce task的槽位

<ul>
<li>
这两种槽位是相互独立的

<li>
具体的数量由cpu 核数和内存决定

<li>
task tracker 会优先使用map task的槽位

</ul>
<li>
对于reduce task, job tracker只是简单的取出运行

<li>
对于map task, job tracker会尽量选取距数据最近的task tracker运行，最好在同一个data node 上

</ol>

<p>
<strong>运行Task:</strong>
</p>
<ol>
<li>
task tracker 分配到一个task, 接下来就是运行这个task

<li>
<strong>Step 8:</strong> 接收所需的文件

<ol>
<li>
将job jar和所需要的一切文件拷到本地系统

<li>
为task创建一个本地目录，并将jar解压

<li>
创建一个　TaskRunner 实例，用于运行task

</ol>
<li>
<strong>Step 9:</strong> 启动一个新的JVM

<li>
<strong>Step 10:</strong> 运行task

<li>
子进程会每隔几秒钟向父进程回报一下task进度，直到task完成

<li>
每一个task都会运行setup和cleanup操作

</ol>

<p>
<strong>进度与状态报告:</strong>
</p>
<ol>
<li>
当一个task运行时，会记录它的进度

<li>
当task进度发生变化时，会设置一个flag,表明需要向task tracker汇报进度

<li>
有一个独立线程会每隔３s检查一个这个flag,如果需要就通知task tracker当前的进度

<li>
task tracker会每５s向job tracker发送一个心跳，如果有信息会随着一起发送

<li>
client的job每秒向job tracker拉一次状态

</ol>
<p>
<img src="mapreduce_classic_progress.png" />
</p>

<p>
<strong>Job完成:</strong>
</p>
<ol>
<li>
job tracker收到最后一个task的完成通知后(cleanup task)

<li>
将job设为成功

<li>
属性 <code>job.end.notification.url</code> 可以配置一个需要http通知的url

</ol>

<h3 id="toc_1.1.2">二代:Yarn(MapReduce 2)</h3>
<p>
在4000个结点以上的集群中，上述方案的水平扩展就会遇到瓶颈，所以有了YARN:
</p>
<ul>
<li>
Yet Another Resource Negotiator

<li>
YARN Application Resource Negotiator

</ul>

<ol>
<li>
YARN通过分解Jobtracker的工作来达到扩大水平扩展能力的手段。jobtracker 的两项职责：

<ol>
<li>
job scheduling 分配task给tasktracker

<li>
监视task的执行进度

</ol>
<li>
YARN将这两项职责分给两个独立的后台进程：

<ul>
<li>
<strong>Resource Manager:</strong> 管理集群上资源的使用

<li>
<strong>Application Master:</strong> 管理运行于集群上的application的生命周期，application对应job 

</ul>
</ol>
  
<p>
<strong>基本思路:</strong>
</p>
<ol>
<li>
此处的application就是mapreduce job

<li>
<code>application master</code> 与 <code>resource manager</code> 协商集群上的资源

<li>
资源表现为容器 <code>containers</code> , 它有一定的内存限制

<li>
application的进程就运行于这些 <code>containers</code> 上

<li>
这些 <code>containers</code> 会被运行于集群结点上的  <code>node manager</code> 监管，避免application使用超过分配给它的资源

<li>
目前集群上的资源就是内存

</ol>

<p>
*与jobtracker相比，每一个application拥有自己的* <code>application master</code> , <strong>运行于application的期间，application就是mapreduce job</strong>
</p>
  
<p>
<img src="mapreduce_yarn.png" />
</p>

<p>
<strong>参与者:</strong>
</p>
<ul>
<li>
<strong>Client:</strong>, MapReduce Job的提交者

<li>
<strong>YARN resource manager:</strong> 管理协调集群上的计算资源

<li>
<strong>YARN node managers:</strong>  启动并监视其所在结点上的计算容器

<li>
<strong>MapReduce application master:</strong> 管理协调一个mapreduce job的所有task. application master 和 job的 task运行于由 <code>resource manager</code> 调度安排并由 <code>node manager</code> 管理的计算容器中

<li>
<strong>Distributed Filesystem:</strong> 通常HDFS,用于共享Job相关的文件

</ul>
 
<p>
<strong>提交Job:</strong>
</p>
<ol>
<li>
<strong>Step 1:</strong> 创建一个JobSubmitter实例，并调用其方法submitJobInternal(). (由Job的方法submit()触发)

<ul>
<li>
和MapReduce 1使用一样的api

<li>
通过属性 <code>mapreduce.framework.name</code> 设置为yarn激活YARN

</ul>
<li>
<strong>Step 2:</strong> 从 <code>resource manager</code> 获取一个新的application id

<li>
client 计算分片

<ul>
<li>
分片也可以在集群中计算

<li>
通过属性 <code>yarn.app.mapreduce.am.compute-splits-in-cluster</code> 激活

</ul>
<li>
<strong>Step 3:</strong> 拷贝application的相关资源到HDFS（jar,configuration,分片结果等），jar文件会有很多份

<li>
<strong>Step 4:</strong> 在 <code>resource manager</code> 调用 submitApplication() 提交一个application

</ol>

<p>
<strong>初始化Job:</strong>
</p>
<ol>
<li>
<strong>Step 5a:</strong> scheduler 分配一个 <code>container</code>

<li>
<strong>Step 5b:</strong> <code>resource manager</code> 在这个 <code>container</code> 上运行 <code>application master</code>, 并在 <code>node manager</code> 的管理下

<li>
<strong>Step 6:</strong> <code>applicaiton master</code> 初始化一个application

<ul>
<li>
<code>applicaiton master</code> 对应类  MRAppMaster

<li>
创建一系列对象追踪job的进度 

<li>
稍后它会从task处得到进度和完成信息

</ul>
<li>
<strong>Step 7:</strong> <code>applicaiton master</code> 从分布式系统中获取计算好的splits

<li>
 <code>application master</code> 创建tasks:

<ul>
<li>
为每一个split创建一个map task

<li>
创建redeuce task, 数量由属性 <code>mapreduce.job.reduces</code> 指定

</ul>
</ol>

<p>
<strong>分配Task:</strong>
</p>

<p>
<strong>运行Task:</strong>
</p>

<p>
<strong>进度与状态报告:</strong>
</p>

<p>
<strong>Job完成:</strong>
</p>

<h2 id="toc_1.2">处理失败</h2>

<h2 id="toc_1.3">Job的调度 </h2>

<h2 id="toc_1.4">Shuffle和排序 </h2>

<h2 id="toc_1.5">Task的运行 </h2>

			</div>

			<div id="bottom">
				&copy; 2012 王兴朝
			</div>
		</div>
	<div>
</body>
</html>
