<!DOCTYPE html>
<html>
<head>

<title>Hadoop File System</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<script type="text/javascript" src="../../js/jquery-1.6.4.min.js"></script>

<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shCore.css">
<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shThemeRDark.css">
<script type="text/javascript" src="../../js/sh/scripts/shCore.js"></script>
<script type="text/javascript" src="../../js/sh/scripts/shAutoloader.js"></script>

<script type="text/javascript" src="../../js/main.js"></script>
<script type="text/javascript" src="../../js/ASCIIMathML.js"></script>

<link rel="Stylesheet" type="text/css" href="../../style.css">
<link rel="Stylesheet" type="text/css" href="../../css/main.css">

</head>
<body>
	<div class="hidden">
		<input id="root_path" type="text" value="../../">
	</div>
	<div id="body-wrapper">
		<div id="container">
			<div id="top">
				<div id="page-title">
					<a href="../../index.html">烂笔头</a>
				</div>
				<ul id="top-nav">
				</ul>
			</div>
			<div id="middle">
				
<div class="toc">
<ul>
<li><a href="#toc_1">Hadoop File System</a>
<ul>
<li><a href="#toc_1.1">HDFS的设计 </a>
<li><a href="#toc_1.2">HDFS</a>
<ul>
<li><a href="#toc_1.2.1">数据块 </a>
<li><a href="#toc_1.2.2">namenode &amp; datanode</a>
<li><a href="#toc_1.2.3">命令行接口 </a>
<li><a href="#toc_1.2.4">基本文件系统操作</a>
<li><a href="#toc_1.2.5">Hadoop文件系统</a>
<li><a href="#toc_1.2.6">接口</a>
<li><a href="#toc_1.2.7">JAVA接口</a>
</ul>
<li><a href="#toc_1.3">数据流 </a>
<ul>
<li><a href="#toc_1.3.1">文件读取剖析</a>
</ul>
</ul>
</ul>
</div>
<h1 id="toc_1">Hadoop File System</h1>
<ul>
<li>
当数据集大小超过一台物理机器，需要对它分区存储到不同的机器上。

<li>
跨机器管理存储的文件系统称之为分布式文件系统，Distributed File System

<li>
HDFS: Hadoop distributed file system.

</ul>

<h2 id="toc_1.1">HDFS的设计 </h2>
<ul>
<li>
<strong>超大文件:</strong> MB GB TB PB 

<li>
<strong>流式数据访问:</strong>

<ul>
<li>
一次写入，多次读入

<li>
每次数据分析涉及数据集中的大部分或全部

</ul>
<li>
<strong>商业硬件:</strong> 并不需要运行在昂贵的可靠的商业硬件上

<li>
<strong>商业硬件:</strong> 并不需要运行在昂贵的可靠的商业硬件上

<li>
<strong>低时间延迟的访问:</strong>

<ul>
<li>
不适合低时间延迟的访问，比如几十毫秒

<li>
为高吞吐量做的优化， 但可能会高时间延迟为代价

</ul>
<li>
<strong>大量小文件:</strong>

<ul>
<li>
元数据存储在Namenode上

<li>
文件总数的大小依赖于Namenode的内存大小 

</ul>
<li>
<strong>不支持多用户写和多用户同时修改:</strong>

</ul>
 
<h2 id="toc_1.2">HDFS</h2>
<h3 id="toc_1.2.1">数据块 </h3>
<ul>
<li>
<strong>磁盘块:</strong> 磁盘进行读写的最小单位, 一般为512字节

<li>
文件系统块是磁盘块的整数倍，一般为几千字节

<li>
HDFS的块默认为64m

<ul>
<li>
小于一个块大小的文件不会占满一个块

<li>
块设的大是为了最小化寻址开销

<li>
块过大也不行，mapreduce一次处理一个块

<li>
块的大小要根据实际情况来调整，比如寻址占传输时间的1/100

</ul>
<li>
使用块的好处

<ul>
<li>
一个文件的大小可以大于任意一个磁盘的大小

<li>
简化了存储子系统，文件的元数据不和块数据存储在一起

<li>
适合备份和容错，任何一个块都有复本。

</ul>
</ul>
<h3 id="toc_1.2.2">namenode &amp; datanode</h3>
<ul>
<li>
管理者 工作者模式

<li>
namenode:

<ul>
<li>
管理者

<li>
管理文件系统的命名空间

<li>
维护文件系统树及树内所的目录与文件

<li>
信息以两个文件永久保存：命名空间镜像文件与编辑日志文件

<li>
记录文件中每个块所在数据结点的信息，但不永久保存，系统启动时重建

</ul>
<li>
datanode:

<ul>
<li>
工作者

<li>
存储校验数据块

<li>
定期向namenode发送数据块列表

</ul>
<li>
失去namenode等于失去文件系统，所namenode容错非常重要：

<ul>
<li>
备份namenode上的元数据，多份同进写

<li>
使用辅助namenode, 定期合并编辑日志生成空间镜像

</ul>
</ul>
<h3 id="toc_1.2.3">命令行接口 </h3>
<h3 id="toc_1.2.4">基本文件系统操作</h3>
<pre  class="brush:bash">
hadoop fs -help
</pre>
  
<h3 id="toc_1.2.5">Hadoop文件系统</h3>
<ul>
<li>
是一个气象的文件系统

<li>
<strong>HDFS只是它的一个实现 </strong>

<li>
抽象类定义了一个文件系统接口：<code>org.apache.hadoop.fs.FileSystem</code>

<li>
还有很多其他实现：Local HDFS HFTP HSFTP HAR hfs FTP S3 

</ul>

<h3 id="toc_1.2.6">接口</h3>
<ul>
<li>
java

<li>
C

<li>
Thrift

<li>
WebDev

<li>
FUSE

<li>


<li>
HDFS两种特定的

<ul>
<li>
HTTP: namenode 50070; datanode 50075

<li>
FTP

</ul>
</ul>
<h3 id="toc_1.2.7">JAVA接口</h3>
<ul>
<li>
<strong>Configuration FileSystem FSDataInpuStream FSDataOutputStream Path FileStatus PathFileter</strong>

<li>
<strong>Configuration</strong>

<ol>
<li>
文件系统的配置

</ol>
<li>
<strong>FileSystem</strong>

<ol>
<li>
代表文件系统

<li>
FileSystem.get(uri, config) :创建

<li>
FSDataInputStream open(path) :获取指定文件的输入流

<li>
FSDataOutputStream create(path) :创建一个文件并获得它的输出流

<li>
FSDataOutputStream append(path) :获取指定文件的输出流，并在其后添加数据

<li>
boolean mkdirs(path) :创建必要但还没有的父目录

<li>
FileStatus getFileStatus(path) : 获取指定文件的文件状态

<li>
FileStatus[] globFileStatus(path) : 获取与文件相匹配的所有文件的文件状态

<li>
FileStatus[] globFileStatus(path， pathFilter) : 获取与文件相匹配的所有文件的文件状态

<li>
FileStatus[] listFileStatus(path) : 用来列目录

<li>
FileStatus[] listFileStatus(path， pathFilter) : 用来列目录

<li>
boolean delete(path, boolean recursive) : 删除文件或目录， 是否递归删除

</ol>
<li>
<strong>FSDataInputStream</strong>

<ol>
<li>
支持随机访问

<li>
seek(long):设置postion

<li>
long getPos():获取postion

<li>
int read(long position, byte[] buffer, int offset, int length)

<li>
void readFully(long position, byte[] buffer, int offset, int length)

<li>
void readFully(byte[] buffer, int offset, int length)

</ol>
<li>
<strong>FSDataOutputStream</strong>

<ol>
<li>
用于写数据 

<li>
支持随机访问

<li>
long getPos():设置postion

<li>
但不允许定位

<li>
只支持对一个打开的文件从头顺序写入， 或从末尾处添加

</ol>
<li>
<strong>FileStatus</strong>

<ol>
<li>
用于查询一个文件状态

</ol>
<li>
<strong>Path</strong>

<ol>
<li>
代表一个文件路径

</ol>
<li>
<strong>PathFileter</strong>

<ol>
<li>
当listStatus时，过滤文件

</ol>
<li>
例子：

<ol>
<li>
读

<li>
写

<li>
目录

<li>
列文件

<li>
删除

</ol>
</ul>
   
<h2 id="toc_1.3">数据流 </h2>
<h3 id="toc_1.3.1">文件读取剖析</h3>
<p>
<img src="reading-data-from-hdfs.png" />
</p>
<ol>
<li>
fileSystem.open打开要读取的文件 

<ul>
<li>
这个文件就是HDFS分布式文件系统中的一个实例

</ul>
<li>
DistributedFileSystem通过RPC调用NameNode确定文件 *起始块* 所在的位置

<ul>
<li>
NameNode返回所有包含该块的DataNode地址

<li>
并按网络距离排序

<li>
比如客户端所在就是一个DataNode, 而该块在此DataNode上刚好存有复本，就会发起本地读取

<li>
返回一个FSDataInputStream对象，供客户端使用. 进而转而封装为HdfsDataInputStream,管理着Namenode和Datanode之间的io

</ul>
<li>
对输入流(FSDataInputStream)调用read()方法

<ul>
<li>
HdfsDataInputStream会从最近的Datanode读入

<li>
不停的read()直到块的末尾

<li>
HdfsDataInpuStream会寻找  <strong>下一个块</strong>  的 <strong>最优Datanode</strong> 继续读取

<li>
对于 *下一块* 也需要向Namenode查询所需的Datanode

<li>
读取完毕调用FSDataInputStream的close()方法进行关闭

<li>
<strong>HdfsDataInputStream与Datanode通信出错时：</strong>

<ol>
<li>
尝试比这个Datanode次邻近的Datanode读取

<li>
它会记住这个出错的Datanode,后续的块也不会从这里读取

<li>
它也会校验读取的数据是否完整,如果发现损坏的块

<li>
如果不完整，再尝试从其他Datanode读取数据之前，通知Namenode

</ol>
<li>
<strong>设计优劣:</strong>

<ol>
<li>
Namenode告知client最佳的Datanode

<li>
client直接从Datenode取数据

<li>
因为Datanode分散在集群中

<li>
所以很容易扩展到大量并发客户端

<li>
Namenode仅提供块位置请求，而不提供数据请求，很高效

<li>
随着客户端的增加， Namenode还是会成为瓶颈

</ol>
</ul>
</ol>

			</div>

			<div id="bottom">
				&copy; 2012 王兴朝
			</div>
		</div>
	<div>
</body>
</html>
