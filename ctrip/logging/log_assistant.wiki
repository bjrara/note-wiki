%title Logging任务调度框架 

=Logging任务调度框架设计文档 =

%toc

==概述 ==

目前logging系统有很多定时job, 比如一些监控，报表等。当时为了快速开发，以脚本的形式存在，并以Crontab的方式运行。
而且这些脚本分布在不同的机器上。这种情况难以维护，情况越来越混乱。

所以需要以一种清晰统一的方式管理这些job.


==设计目标 ==
# 设计一套通用的数据处理框架，可预生成各类报表和报表图片
# 易扩展，很方便的添加新的需求

==总体架构 ==
下面是组件的组成：

{{data-processing.png}}

* *RawDataCollector:* 
  # 负责收集报表生成的原始数据
  # 需要定义出原始数据应该满足的一种模式
  # 提供接口，方便添加原始数据
  # 原始数据会存入HBase
* *DataHouse:*
  # 原始数据和加工结果存储的地方
  # 加工结果可能作为原始数据进一步加工
  # 所以原始数据和加工结果要使用类似的存储结构
* *Report Manufactory:*
  # 负责将原始数据加工成可以直接使用的报表
  # 加式的结果可以进一步加工
  # 加工方式要有通用性，做到和业务无关
  # 可以预定义几种加工方式

==核心算法 ==
===需求 ===
简单来说我们需要一个对象的度量数值在一小时内的变化情况，在一天内的变化情况，在一周内的变化情况 ... ...

* 如果是一小时，将以分钟为单位聚合，产生60个点
* 如果是一天，将以小时为单位聚合，产生24个点
* 如果是一周，将以天为单位聚合，产生7个点

而原始数据就是以分钟为单位收集到的数据，然后处理引擎就可以以此产生最终的小时结果，再以小时结果产生天的结果，再以天的结果产生周的结果 ...

另一种维度的聚合，除了时间维度聚合外，还需要一个范围的聚合，比如一个对象内某种子对象在这个数值上的变化。

所以原始数据将是以最小对象为单位收集的，然后逐步聚合成大对象。

可以来看一个具体的例子, 比如有个应用HotelBooking, 拥有10台服务器Server1 ~ Server10, 想看它的一个url /hotels的访问次数分布情况。
# 可以收集这个url /hotels 每分钟在每台server上的访问次数
# 经过聚合可以得到这个url每小时在每台server上访问次数分布
# 上面再聚合可以得到这个url在整个应用上每小时的访问次数分布
# 以此类推可以得到这个url在每天在每台server或整个应用上的分布情况
# 在双维度上不停聚合，就可以得到想要的结果，双维度就是时间维度和范围维度，他们都是从小向大的聚合。

===设计一种结构 ===
为了做到与业务无关和通用性，需要设计一种结构，方便在双维度上聚合。

| type | timestamp | target | p0 | p1 | p2 | p3 | value |

* *type:* 说明要统计的类型，比如count,将决定最终聚合的具体算法，最后将提供有限的几种类型
* *timestamp:*:指明该条记录是哪个时间点的聚合，比如哪一分钟，哪一小时，哪一天
  # 对于不同时间刻度的时间聚合可以放到不同的地方，在HBase中就是不同的表中
  # 这样对于timestamp代表的是小时聚合还是天聚合就没有疑问了。
* *target:*:表明对哪种对象的统计，比如'URL','SQL','WEBSERVICE' etc.
* *p0 ~ pN*: 代表范围，从最大向小过度
  # p0 代表一个具体的appId
  # p1 代表一个具体的url
  # p2 代表一个具体的server
* type与target可以合并成一个字段

===加工算法 ===
有了数据，如何进行进一步加工,可以将一次时间聚合作为一次操作，
在此操作过程中，流式扫描区间内的记录，按范围维度聚合成想要的结果
| p0p1p2..pN | p0p1p2..pN-1 | ... | p0p1p2 | p0p1 | p0 |

{{report-aa.png}}

# 首先决定聚合某个时间段的度量值，比如某小时，某天
# 从对应的数据源逐条获取该时间段的记录
# 对于每条记录，产生所需每种范围的聚合记录
# 并判定如果是已聚合完的可以flush出去

==HBase Schema 设计 ==
计划使用HBase进行数据存储，并根据时间维度进行分表存储。

{{report-hbase.png}}

# 分钟级的原始数据将存储在表 `freeway.report.minute` 里
# 小时级的数据将存储在表 `freeway.report.hour` 里, 由表 `freeway.report.minute`里的数据聚合而来
# 天级的数据将存储在表`freeway.report.day`里, 由表`freeway.report.hour`里的数据聚合而来
# 周级的数据将存储在表`freeway.report.week`里, 由表`freeway.report.day`里的数据聚合而来

*而这些表将采用统一的schema设计。 *
| RowKey | >         | >      | >  | >  | >  | >  | Column Family | >          |
| \/     | >         | >      | >  | >  | >  | >  | data          | image      |
|--------|-----------|--------|----|----|----|----|---------------|------------|
| type   | timestamp | target | p0 | p1 | p2 | p3 | report data   | image data |

* RowKey的含义参考上面所说
* Column Family:
  * data, 存放具体的数字数据
  * image, 根据数据生成的报表图片，可以直接使用

==我们需要的报表 ==
目前我们需要的报表分以下几种类型：
* Count:访问次数
* Latency：latency分布
* Avg：平均耗时
* Min：最小耗时
* Max：最大耗时

需要对以下对象进行统计：
* URL: 携程的URL
* SQL: DAL层的Sql执行
* WebService: 产品之间的WebService调用

数据采集：
# 目前的数据来源主要来自CFramework中的框架埋点
# 可以在Writer中将此类metrics转换为原始数据

===URL Report ===
以URL Report为例，来看数据来源：
# Visit Count:
  * Arch.CFramework.StartUp.Tracing.Url_HttpRequest_Count
# Latency Distribution:
  * 暂无metrics支持
  * 自身统计或等metrics埋点
# Avg Latency:
  * Arch.CFramework.StartUp.Tracing.Url_HttpRequest_Cost_Avg
  * 问题是无法聚合，需要添加count的tag
# Min Latency:
  * Arch.CFramework.StartUp.Tracing.Url_HttpRequest_Cost_Min
# Max Latency:
  * Arch.CFramework.StartUp.Tracing.Url_HttpRequest_Cost_Max
# Long Url Count:
# Long Url Ratio:
# Top N Visited Url:
# Bottom N Visited Url:


==数据采集模块 ==
{{report-data-collector.png}}

# 应该假定数据源，是存在多种的
# *Collect Interface*:暴露适合的数据采集接口
  * 可以添加一条分钟级的原始数据
  * 可以更改已存在的一条数据
# *Domain Object:* 定义出合适的领域模型
  * 易于在各组件之间传递数据
  * 使内存中的数据语义化
  * 易于计算
# *Persistent Interface*:数据持久化接口
  * 将数据持久到HBase中
  * 实现接口解耦

==数据统计聚合模块 ==
{{report-data-manufactory.png}}

* *Task:*
  * 把数据操作包装成一个定时调度的Task
  * 每小时执行一次上一小时的聚合操作
  * 每天执行一次前一天的聚合操作
* *DataProcessor:*
  * 数据聚合引擎
  * 上面核心算法的实现
* *ImageGenerator:*
  * 图片生成器
  * 为需要的每条数据预先生成报表图片
  * 根据策略可以添加基准线

==RestApi ==
{{report-api.png}}

目前大概会提供四种数据的报表log, url, sql, webservice.
需要提供友好的api,根据参数获取报表数据或图片
# log:
  * 提供Error Count的报表
# url, log, webservice类似，提供上面url所需的报表：
  * Visit Count
  * Latency Distribution
  * Avg Latency
  * Min Latency
  * Max Latency
  * Long Cost Count
  * Long Cost Ratio
  * Top N Visited
  * Bottom N Visited

==新增Domain ==
需要为了用到的数据载体定义出领域模型。
