%title 报表数据采集框架设计文档 

=报表数据采集框架设计文档 =

%toc

==概述 ==

目前logging系统采集到了数据，接下来需要以一种好的方式展现给用户，给用户提供更多的帮助。
而图形方式的报表将是一种很好的选择。比如日志报表、URL报表、SQL报表、WEBService报表等。

使用metrics可以是种方案，但metrics在速度上有一定的限制，因为它是即时计算。所以想到了使用预先生成结果，使用时可以直接使用，提升用户体验，并可以保留历史统计数据。

由于基础数据量庞大和以后的易扩展和通用性，比较好的选择是设计一套通用的预处理框架。

==设计目标 ==
# 设计一套通用的数据处理框架，可预生成各类报表和报表图片
# 易扩展，很方便的添加新的需求

==总体架构 ==
下面是组件的组成：

{{data-processing.png}}

* *RawDataCollector:* 
  # 负责收集报表生成的原始数据
  # 需要定义出原始数据应该满足的一种模式
  # 提供接口，方便添加原始数据
  # 原始数据会存入HBase
* *DataHouse:*
  # 原始数据和加工结果存储的地方
  # 加工结果可能作为原始数据进一步加工
  # 所以原始数据和加工结果要使用类似的存储结构
* *Report Manufactory:*
  # 负责将原始数据加工成可以直接使用的报表
  # 加式的结果可以进一步加工
  # 加工方式要有通用性，做到和业务无关
  # 可以预定义几种加工方式

==核心算法 ==
===需求 ===
简单来说我们需要一个对象的度量数值在一小时内的变化情况，在一天内的变化情况，在一周内的变化情况 ... ...

* 如果是一小时，将以分钟为单位聚合，产生60个点
* 如果是一天，将以小时为单位聚合，产生24个点
* 如果是一周，将以天为单位聚合，产生7个点

而原始数据就是以分钟为单位收集到的数据，然后处理引擎就可以以此产生最终的小时结果，再以小时结果产生天的结果，再以天的结果产生周的结果 ...

另一种维度的聚合，除了时间维度聚合外，还需要一个范围的聚合，比如一个对象内某种子对象在这个数值上的变化。

所以原始数据将是以最小对象为单位收集的，然后逐步聚合成大对象。

可以来看一个具体的例子, 比如有个应用HotelBooking, 拥有10台服务器Server1 ~ Server10, 想看它的一个url /hotels的访问次数分布情况。
# 可以收集这个url /hotels 每分钟在每台server上的访问次数
# 经过聚合可以得到这个url每小时在每台server上访问次数分布
# 上面再聚合可以得到这个url在整个应用上每小时的访问次数分布
# 以此类推可以得到这个url在每天在每台server或整个应用上的分布情况
# 在双维度上不停聚合，就可以得到想要的结果，双维度就是时间维度和范围维度，他们都是从小向大的聚合。

===设计一种结构 ===
为了做到与业务无关和通用性，需要设计一种结构，方便在双维度上聚合。

| type | timestamp | target | p0 | p1 | p2 | p3 | value |

* *type:* 说明要统计的类型，比如count,将决定最终聚合的具体算法，最后将提供有限的几种类型
* *timestamp:*:指明该条记录是哪个时间点的聚合，比如哪一分钟，哪一小时，哪一天
  # 对于不同时间刻度的时间聚合可以放到不同的地方，在HBase中就是不同的表中
  # 这样对于timestamp代表的是小时聚合还是天聚合就没有疑问了。
* *target:*:表明对哪种对象的统计，比如'URL','SQL','WEBSERVICE' etc.
* *p0 ~ pN*: 代表范围，从最大向小过度
  # p0 代表一个具体的appId
  # p1 代表一个具体的url
  # p2 代表一个具体的server
* type与target可以合并成一个字段

===加工算法 ===
有了数据，如何进行进一步加工,可以将一次时间聚合作为一次操作，
在此操作过程中，流式扫描区间内的记录，按范围维度聚合成想要的结果
| p0p1p2..pN | p0p1p2..pN-1 | ... | p0p1p2 | p0p1 | p0 |

{{report-aa.png}}

# 首先决定聚合某个时间段的度量值，比如某小时，某天
# 从对应的数据源逐条获取该时间段的记录
# 对于每条记录，产生所需每种范围的聚合记录
# 并判定如果是已聚合完的可以flush出去

==HBase Schema 设计 ==
计划使用HBase进行数据存储，并根据时间维度进行分表存储。

{{report-hbase.png}}

# 分钟级的原始数据将存储在表 `freeway.report.minute` 里
# 小时级的数据将存储在表 `freeway.report.hour` 里, 由表 `freeway.report.minute`里的数据聚合而来
# 天级的数据将存储在表`freeway.report.day`里, 由表`freeway.report.hour`里的数据聚合而来
# 周级的数据将存储在表`freeway.report.week`里, 由表`freeway.report.day`里的数据聚合而来

*而这些表将采用统一的schema设计。 *
| RowKey | >         | >      | >  | >  | >  | >  | Column Family | >          |
| \/     | >         | >      | >  | >  | >  | >  | data          | image      |
|--------|-----------|--------|----|----|----|----|---------------|------------|
| type   | timestamp | target | p0 | p1 | p2 | p3 | report data   | image data |

* RowKey的含义参考上面所说
* Column Family:
  * data, 存放具体的数字数据
  * image, 根据数据生成的报表图片，可以直接使用

==数据采集模块 ==
{{report-data-collector.png}}

# 应该假定数据源，是存在多种的
# *Collect Interface*:暴露适合的数据采集接口
  * 可以添加一条分钟级的原始数据
  * 可以更改已存在的一条数据
# *Domain Object:* 定义出合适的领域模型
  * 易于在各组件之间传递数据
  * 使内存中的数据语义化
  * 易于计算
# *Persistent Interface*:数据持久化接口
  * 将数据持久到HBase中
  * 实现接口解耦

==数据统计聚合模块 ==
{{report-data-manufactory.png}}

==RestApi ==
{{report-api.png}}

==新增Domain ==
